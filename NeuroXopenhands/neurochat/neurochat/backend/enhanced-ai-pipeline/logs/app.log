{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-05 13:25:36'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:37'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-05 13:25:37'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-05 13:25:37'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:816:11)\n' +
    '    at NativeConnection.openUri (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:120:9)\n' +
    '    at async Server.initialize (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:33:7)\n' +
    '    at async Server.start (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:658:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-05 13:25:42',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongodb/lib/sdam/topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:581:17)\n' +
    '    at process.processTimers (node:internal/timers:519:7)',
  component: 'mongodb',
  timestamp: '2025-09-05 13:25:42',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 2665,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-05 13:26:36',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: '/home/user/webapp/7-main/new-main/neurochat/workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-05 19:30:19'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-05 19:30:19'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:20'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-05 19:30:20'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-05 19:30:20'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:816:11)\n' +
    '    at NativeConnection.openUri (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:120:9)\n' +
    '    at async Server.initialize (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:34:7)\n' +
    '    at async Server.start (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:677:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-05 19:30:25',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongodb/lib/sdam/topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:581:17)\n' +
    '    at process.processTimers (node:internal/timers:519:7)',
  component: 'mongodb',
  timestamp: '2025-09-05 19:30:25',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 4120,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\New folder\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 6884,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-15 18:46:24'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-15 18:46:34',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/favicon.ico',
  statusCode: 404,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-15 18:46:34',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-15 18:46:50',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: "C:\\Users\\Administrator\\Desktop\\YH's projet\\NeuroXopenhands\\neurochat\\neurochat\\workspaces",
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 4620,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-15 21:18:23'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-15 21:18:38',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/favicon.ico',
  statusCode: 404,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-15 21:18:38',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-15 21:19:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: "C:\\Users\\Administrator\\Desktop\\YH's projet\\NeuroXopenhands\\neurochat\\neurochat\\workspaces",
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 4324,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-16 11:51:04'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 8,
  userId: null,
  timestamp: '2025-09-16 11:51:10',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-16 11:52:59',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 18868,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 17:49:30'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 10,
  userId: null,
  timestamp: '2025-09-17 17:49:34',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 9,
  userId: null,
  timestamp: '2025-09-17 18:41:20',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:35'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 10120,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 21:14:35'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 8,
  userId: null,
  timestamp: '2025-09-17 21:14:39',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 13732,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 22:05:14'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 12,
  userId: null,
  timestamp: '2025-09-17 22:05:24',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:06:03'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '8b7201f1-2b25-4092-9c73-faff4b6db8ea',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-17 22:06:03'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 315,
  userId: null,
  timestamp: '2025-09-17 22:06:03',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 14824,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 22:20:41'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 40,
  userId: null,
  timestamp: '2025-09-17 22:20:48',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:21:12'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'fe80cbf8-613e-4a5a-864e-0458f0d1db14',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-17 22:21:12'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 362,
  userId: null,
  timestamp: '2025-09-17 22:21:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 17292,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 22:51:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 12,
  userId: null,
  timestamp: '2025-09-17 22:51:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  status: 401,
  level: 'warn',
  message: 'Authentication failed for openai',
  timestamp: '2025-09-17 22:52:05'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:52:05'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '76c9f61e-3e95-4c5b-9f9d-b31ef5ef3f62',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-17 22:52:05'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 1768,
  userId: null,
  timestamp: '2025-09-17 22:52:05',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-17 23:26:03',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 19388,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-18 18:31:15'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-18 18:31:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 21,
  userId: null,
  timestamp: '2025-09-18 18:35:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3a65dddc-60a1-472b-9951-ec1178de75c2',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '3a65dddc-60a1-472b-9951-ec1178de75c2',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'c9554eeb-1706-4175-a56d-262b693305db',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 0,
  responseTime: 1,
  error: 'No API key available for provider: google',
  timestamp: '2025-09-18 18:35:18',
  level: 'info',
  message: 'Model Call'
}
{
  message: 'Retrying gemini-1.5-flash in 1000ms (attempt 1/3)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '41608ebe-288b-4d70-aab6-69f6b8708d26',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:35:19'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 0,
  responseTime: 1,
  error: 'No API key available for provider: google',
  timestamp: '2025-09-18 18:35:19',
  level: 'info',
  message: 'Model Call'
}
{
  message: 'Retrying gemini-1.5-flash in 2000ms (attempt 2/3)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:35:19'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '9fccef23-c379-4c40-851f-24af87715e9a',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 0,
  responseTime: 0,
  error: 'No API key available for provider: google',
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3a65dddc-60a1-472b-9951-ec1178de75c2',
  error: 'NETWORK_ERROR',
  level: 'error',
  message: 'Direct processing failed',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'NETWORK_ERROR',
  level: 'warn',
  message: 'Direct processing failed, falling back to queue',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e',
  queryLength: 2,
  hasFiles: false,
  options: {
    selectedModel: 'gemini-1.5-flash',
    selectedModels: [ 'gemini-1.5-flash' ],
    conversationId: 'assistant_1758216918942',
    workspaceId: 'default',
    priority: 0,
    skipCache: false,
    enhanceWithKnowledge: true,
    enableLearning: true
  },
  level: 'info',
  message: 'New query submitted',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  priority: 0,
  query: 'hi',
  level: 'info',
  message: 'Query job added to queue',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  query: 'hi',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '09827f6f-441a-4933-b53d-d6cf9cd7e1a9',
  timestamp: '2025-09-18 18:35:22',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '21',
  timestamp: '2025-09-18 18:35:22',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/v1/queries',
  statusCode: 202,
  responseTime: 15,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '21',
  jobType: 'processQuery',
  attempts: 1,
  data: {
    query: 'hi',
    options: {
      selectedModel: 'gemini-1.5-flash',
      selectedModels: [ 'gemini-1.5-flash' ],
      conversationId: 'assistant_1758216918942',
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e'
    },
    requestId: '3975a11e-838b-4945-a150-631825f20e77'
  },
  timestamp: '2025-09-18 18:35:22',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 3062,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '36f2d860-5959-40ff-b26c-cbbaaba25586',
  queryId: '3975a11e-838b-4945-a150-631825f20e77',
  level: 'info',
  message: 'Query result requested',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/queries/3975a11e-838b-4945-a150-631825f20e77',
  statusCode: 404,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/3975a11e-838b-4945-a150-631825f20e77',
  statusCode: 200,
  responseTime: 7,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  query: 'hi',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:35:24'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '0ac082ed-a976-4ab6-b66c-d3a5cef5145f',
  timestamp: '2025-09-18 18:35:24',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '21',
  timestamp: '2025-09-18 18:35:24',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '21',
  jobType: 'processQuery',
  attempts: 2,
  data: {
    query: 'hi',
    options: {
      selectedModel: 'gemini-1.5-flash',
      selectedModels: [ 'gemini-1.5-flash' ],
      conversationId: 'assistant_1758216918942',
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e'
    },
    requestId: '3975a11e-838b-4945-a150-631825f20e77'
  },
  timestamp: '2025-09-18 18:35:24',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  query: 'hi',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:35:30'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '97531f11-3854-415a-b7b2-94f2b2394990',
  timestamp: '2025-09-18 18:35:30',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '21',
  timestamp: '2025-09-18 18:35:30',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '21',
  jobType: 'processQuery',
  attempts: 3,
  data: {
    query: 'hi',
    options: {
      selectedModel: 'gemini-1.5-flash',
      selectedModels: [ 'gemini-1.5-flash' ],
      conversationId: 'assistant_1758216918942',
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e'
    },
    requestId: '3975a11e-838b-4945-a150-631825f20e77'
  },
  timestamp: '2025-09-18 18:35:30',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:38:41',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:40:57'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:40:57'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'f1db990f-b44b-4b37-84d8-389f2aad6250',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-18 18:40:57'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 331,
  userId: null,
  timestamp: '2025-09-18 18:40:57',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '1b38b68d-82f2-4a0e-a8a3-c6b63a147140',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 954,
  error: null,
  timestamp: '2025-09-18 18:41:01',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  processingTime: 956,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:41:01'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 960,
  userId: null,
  timestamp: '2025-09-18 18:41:01',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:41:01',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 8,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b0e7df2d-b08b-4734-a943-7889b133a54b',
  query: 'hi there',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'b0e7df2d-b08b-4734-a943-7889b133a54b',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'd0d14a6e-1271-4360-94b1-b45587af8ba8',
  modelId: 'gemini-1.5-flash',
  promptLength: 8,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 8,
  responseLength: 36,
  responseTime: 664,
  error: null,
  timestamp: '2025-09-18 18:41:09',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b0e7df2d-b08b-4734-a943-7889b133a54b',
  processingTime: 665,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:41:09'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 667,
  userId: null,
  timestamp: '2025-09-18 18:41:09',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/b0e7df2d-b08b-4734-a943-7889b133a54b',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:41:09',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '8364e70a-e120-47c9-98f4-1795c5b18678',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '8364e70a-e120-47c9-98f4-1795c5b18678',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a6a1eac8-999b-4240-8147-2365163468b6',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 36,
  responseTime: 489,
  error: null,
  timestamp: '2025-09-18 18:41:18',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '8364e70a-e120-47c9-98f4-1795c5b18678',
  processingTime: 490,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 493,
  userId: null,
  timestamp: '2025-09-18 18:41:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/8364e70a-e120-47c9-98f4-1795c5b18678',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:41:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 81,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  query: 'hi can you help me to find the best ai models for coding , my budjet is 20 dollar',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '29b578ae-adb8-496a-86da-e54ce4f31a4e',
  modelId: 'gemini-1.5-flash',
  promptLength: 81,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 81,
  responseLength: 2221,
  responseTime: 3715,
  error: null,
  timestamp: '2025-09-18 18:42:00',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  processingTime: 3716,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:42:00'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 3718,
  userId: null,
  timestamp: '2025-09-18 18:42:00',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:42:00',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 48,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  query: 'next time answer with the name of the model only',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '2f4d1a16-c36d-4c97-af86-98df7d9342eb',
  modelId: 'gemini-1.5-flash',
  promptLength: 48,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 48,
  responseLength: 5,
  responseTime: 503,
  error: null,
  timestamp: '2025-09-18 18:42:28',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  processingTime: 505,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 507,
  userId: null,
  timestamp: '2025-09-18 18:42:28',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:42:28',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 32,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  query: 'ok now what is the models again?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ff82b732-26f5-493e-90ad-c25227092b19',
  modelId: 'gemini-1.5-flash',
  promptLength: 32,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 32,
  responseLength: 245,
  responseTime: 845,
  error: null,
  timestamp: '2025-09-18 18:42:49',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  processingTime: 849,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:42:49'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 852,
  userId: null,
  timestamp: '2025-09-18 18:42:49',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:42:49',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  query: 'ok',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'dccef9d0-73d0-4a6e-a543-6ee78557cccf',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 33,
  responseTime: 504,
  error: null,
  timestamp: '2025-09-18 18:43:22',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  processingTime: 505,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:43:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 507,
  userId: null,
  timestamp: '2025-09-18 18:43:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:43:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 6,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  query: 'no thx',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a237c5c5-b1c2-4741-a610-80b03609b926',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  responseLength: 51,
  responseTime: 576,
  error: null,
  timestamp: '2025-09-18 18:43:32',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  processingTime: 578,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:43:32'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 580,
  userId: null,
  timestamp: '2025-09-18 18:43:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  statusCode: 200,
  responseTime: 0,
  userId: null,
  timestamp: '2025-09-18 18:43:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 30,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '558d928c-529b-4704-9522-c06c55263916',
  query: 'what is the time now in london',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '558d928c-529b-4704-9522-c06c55263916',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '023a1674-f1fa-41ee-84b1-65bb825a4a54',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  responseLength: 233,
  responseTime: 917,
  error: null,
  timestamp: '2025-09-18 18:43:58',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '558d928c-529b-4704-9522-c06c55263916',
  processingTime: 919,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:43:58'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 921,
  userId: null,
  timestamp: '2025-09-18 18:43:58',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/558d928c-529b-4704-9522-c06c55263916',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:43:58',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 19,
  userId: null,
  timestamp: '2025-09-18 18:44:10',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:47:19',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-pro-002',
  models: [ 'gemini-1.5-pro-002' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '21b766f3-ba88-49fb-be7f-1c58c4cb7bc1',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-pro-002' ],
  taskId: '21b766f3-ba88-49fb-be7f-1c58c4cb7bc1',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ad761492-ce1d-4625-b269-dc576fdcdab1',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 281,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ad761492-ce1d-4625-b269-dc576fdcdab1',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '21b766f3-ba88-49fb-be7f-1c58c4cb7bc1',
  error: 'RATE_LIMIT',
  level: 'error',
  message: 'Direct processing failed',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'RATE_LIMIT',
  level: 'warn',
  message: 'Direct processing failed, falling back to queue',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a',
  queryLength: 50,
  hasFiles: false,
  options: {
    selectedModel: 'gemini-1.5-pro-002',
    selectedModels: [ 'gemini-1.5-pro-002' ],
    conversationId: 'conv_1758217649347_flu3zfddi',
    fileIds: [],
    workspaceId: 'default',
    priority: 0,
    skipCache: false,
    enhanceWithKnowledge: true,
    enableLearning: true
  },
  level: 'info',
  message: 'New query submitted',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  priority: 0,
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Query job added to queue',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'c849cfbe-eb3b-4981-b6e4-6ccb63ead099',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/v1/queries',
  statusCode: 202,
  responseTime: 20,
  userId: null,
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 309,
  userId: null,
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a73874b8-a5ef-470d-b426-9707f997b476',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 98,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a73874b8-a5ef-470d-b426-9707f997b476',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'c849cfbe-eb3b-4981-b6e4-6ccb63ead099',
  totalTime: 102,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: 'c849cfbe-eb3b-4981-b6e4-6ccb63ead099',
  timestamp: '2025-09-18 18:47:29',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '22',
  timestamp: '2025-09-18 18:47:29',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '22',
  jobType: 'processQuery',
  attempts: 1,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758217649347_flu3zfddi',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a'
    },
    requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a'
  },
  timestamp: '2025-09-18 18:47:29',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'e214c142-71e7-4e46-97c1-c18412b5d706',
  queryId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  level: 'info',
  message: 'Query result requested',
  timestamp: '2025-09-18 18:47:30'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/queries/8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  statusCode: 404,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:47:30',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-18 18:47:30',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:47:31'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'fa490cea-2e92-4628-8235-53a0037f0bae',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-18 18:47:31'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '7e73d04f-46e3-4d50-a6db-17333f21f57e',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:31'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 93,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:32',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '7e73d04f-46e3-4d50-a6db-17333f21f57e',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:32'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'fa490cea-2e92-4628-8235-53a0037f0bae',
  totalTime: 98,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-18 18:47:32'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: 'fa490cea-2e92-4628-8235-53a0037f0bae',
  timestamp: '2025-09-18 18:47:32',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '22',
  timestamp: '2025-09-18 18:47:32',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '22',
  jobType: 'processQuery',
  attempts: 2,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758217649347_flu3zfddi',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a'
    },
    requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a'
  },
  timestamp: '2025-09-18 18:47:32',
  level: 'error'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:47:35'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:47:35'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'a0560dc1-2af3-49bb-8de8-3deb532c9d35',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-18 18:47:35'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 77,
  userId: null,
  timestamp: '2025-09-18 18:47:35',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '3a56162c-d9b0-4d72-ae60-81b6ac1d7c34',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'b4ce98c7-a46f-4d0b-8f22-6ce9c29cdc72',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 90,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:38',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'b4ce98c7-a46f-4d0b-8f22-6ce9c29cdc72',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '3a56162c-d9b0-4d72-ae60-81b6ac1d7c34',
  totalTime: 91,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '3a56162c-d9b0-4d72-ae60-81b6ac1d7c34',
  timestamp: '2025-09-18 18:47:38',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '22',
  timestamp: '2025-09-18 18:47:38',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '22',
  jobType: 'processQuery',
  attempts: 3,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758217649347_flu3zfddi',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a'
    },
    requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a'
  },
  timestamp: '2025-09-18 18:47:38',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '7f287bfd-a665-4802-b3e4-3c0efc791e49',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '7f287bfd-a665-4802-b3e4-3c0efc791e49',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '64c8b27b-bd3c-4ce3-bf3f-82fcee663562',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 423,
  error: null,
  timestamp: '2025-09-18 18:47:42',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '7f287bfd-a665-4802-b3e4-3c0efc791e49',
  processingTime: 423,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 425,
  userId: null,
  timestamp: '2025-09-18 18:47:42',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/7f287bfd-a665-4802-b3e4-3c0efc791e49',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:47:43',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'dce28dca-c169-428f-b2cd-39af0b9c2203',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'dce28dca-c169-428f-b2cd-39af0b9c2203',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a35ab8ee-e59d-4029-ba8a-da8b42f2d119',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  responseLength: 3866,
  responseTime: 6411,
  error: null,
  timestamp: '2025-09-18 18:47:57',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'dce28dca-c169-428f-b2cd-39af0b9c2203',
  processingTime: 6411,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:47:57'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 6414,
  userId: null,
  timestamp: '2025-09-18 18:47:57',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/dce28dca-c169-428f-b2cd-39af0b9c2203',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:47:58',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 3,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  query: 'hi ',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '69a83dc8-d2d2-4ef5-952a-96de40b2782e',
  modelId: 'gemini-1.5-flash',
  promptLength: 3,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 3,
  responseLength: 36,
  responseTime: 543,
  error: null,
  timestamp: '2025-09-18 18:50:59',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  processingTime: 545,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:50:59'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 548,
  userId: null,
  timestamp: '2025-09-18 18:50:59',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:50:59',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 56,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '89101e39-7bb3-42af-b2d8-8f707448a0b0',
  query: 'i want you to help me find the best ai models for coding',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '89101e39-7bb3-42af-b2d8-8f707448a0b0',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '82c30513-d578-48a5-b936-24e9138be46b',
  modelId: 'gemini-1.5-flash',
  promptLength: 56,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 56,
  responseLength: 3386,
  responseTime: 5433,
  error: null,
  timestamp: '2025-09-18 18:51:32',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '89101e39-7bb3-42af-b2d8-8f707448a0b0',
  processingTime: 5434,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:51:32'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 5437,
  userId: null,
  timestamp: '2025-09-18 18:51:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/89101e39-7bb3-42af-b2d8-8f707448a0b0',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:51:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 10,
  userId: null,
  timestamp: '2025-09-18 18:54:08',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-18 18:57:42',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 30,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '1d655734-4520-4c5d-9233-e9b5b7b7256a',
  query: 'give me the name of the best 3',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '1d655734-4520-4c5d-9233-e9b5b7b7256a',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '797367d3-2fff-4dfc-965a-41e976fd8715',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  responseLength: 189,
  responseTime: 887,
  error: null,
  timestamp: '2025-09-18 19:00:56',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '1d655734-4520-4c5d-9233-e9b5b7b7256a',
  processingTime: 887,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:00:56'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 889,
  userId: null,
  timestamp: '2025-09-18 19:00:56',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/1d655734-4520-4c5d-9233-e9b5b7b7256a',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:00:56',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 9,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ab350d65-9c88-4e4e-b590-26055980c125',
  query: 'ai models',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'ab350d65-9c88-4e4e-b590-26055980c125',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '8307826d-05e5-41a7-aed1-1ff424eaad9c',
  modelId: 'gemini-1.5-flash',
  promptLength: 9,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 9,
  responseLength: 3828,
  responseTime: 5821,
  error: null,
  timestamp: '2025-09-18 19:01:18',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ab350d65-9c88-4e4e-b590-26055980c125',
  processingTime: 5822,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:01:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 5825,
  userId: null,
  timestamp: '2025-09-18 19:01:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/ab350d65-9c88-4e4e-b590-26055980c125',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:01:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 75,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  query: 'give me the name of the best 3 ai models only with  the budjet of 20 doller',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '99e2b907-fa3b-4548-bc16-8c30ca5817f0',
  modelId: 'gemini-1.5-flash',
  promptLength: 75,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 75,
  responseLength: 759,
  responseTime: 1625,
  error: null,
  timestamp: '2025-09-18 19:02:11',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  processingTime: 1625,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:02:11'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 1627,
  userId: null,
  timestamp: '2025-09-18 19:02:11',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:02:11',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 88,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '24eba698-d8cb-45df-b42a-de49bbc128ac',
  query: 'give me the name of the best 3 ai models only in programing with the budjet of 20 doller',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '24eba698-d8cb-45df-b42a-de49bbc128ac',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a668bd4b-5b1e-4738-a485-66d1c72f46f5',
  modelId: 'gemini-1.5-flash',
  promptLength: 88,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 88,
  responseLength: 1794,
  responseTime: 3169,
  error: null,
  timestamp: '2025-09-18 19:02:36',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '24eba698-d8cb-45df-b42a-de49bbc128ac',
  processingTime: 3172,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:02:36'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 3174,
  userId: null,
  timestamp: '2025-09-18 19:02:36',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/24eba698-d8cb-45df-b42a-de49bbc128ac',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:02:36',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 113,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  query: 'give me the name of the best 3 ai models only in coding with the budjet of 20 doller answer with the',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'bc8d1fb9-07f2-409e-a16a-9aa51eaf26fb',
  modelId: 'gemini-1.5-flash',
  promptLength: 113,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 113,
  responseLength: 331,
  responseTime: 1033,
  error: null,
  timestamp: '2025-09-18 19:03:12',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  processingTime: 1035,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:03:12'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 1036,
  userId: null,
  timestamp: '2025-09-18 19:03:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:03:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 11192,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-18 21:43:50'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-18 21:43:57',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 23:20:52'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 21004,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-18 23:20:52'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 7,
  userId: null,
  timestamp: '2025-09-18 23:20:56',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-18 23:21:43',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 23:22:09',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 07:42:08'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-19 07:42:08'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:09'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-19 07:42:09'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-19 07:42:09'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:14'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:816:11)\n' +
    '    at NativeConnection.openUri (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:120:9)\n' +
    '    at async Server.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:34:7)\n' +
    '    at async Server.start (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:739:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-19 07:42:14',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-19 07:42:14'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:14'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongodb\\lib\\sdam\\topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:594:17)\n' +
    '    at process.processTimers (node:internal/timers:529:7)',
  component: 'mongodb',
  timestamp: '2025-09-19 07:42:14',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:14'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:14'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:14'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:14'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 19016,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 07:42:14'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 16,
  userId: null,
  timestamp: '2025-09-19 07:42:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-19 07:42:35',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:49'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:42:49'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '90138efc-e86d-4231-90c4-ca798b1fef6b',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-19 07:42:49'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 465,
  userId: null,
  timestamp: '2025-09-19 07:42:49',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-19 07:42:54'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3afab2fe-e2d3-4476-8996-16693180b6ce',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-19 07:42:54'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '3afab2fe-e2d3-4476-8996-16693180b6ce',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-19 07:42:54'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '07db1d93-f07c-4506-b046-5fe7e6abe80b',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-19 07:42:54'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 492,
  error: null,
  timestamp: '2025-09-19 07:42:55',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3afab2fe-e2d3-4476-8996-16693180b6ce',
  processingTime: 495,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-19 07:42:55'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 499,
  userId: null,
  timestamp: '2025-09-19 07:42:55',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/3afab2fe-e2d3-4476-8996-16693180b6ce',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-19 07:42:55',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-19 07:43:01'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'd7e7ae47-6720-4ff6-b540-64ea1fa4eda9',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-19 07:43:01'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'd7e7ae47-6720-4ff6-b540-64ea1fa4eda9',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-19 07:43:01'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '8eef9ff0-74e2-4811-b1d5-964e6b09688b',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-19 07:43:01'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 36,
  responseTime: 728,
  error: null,
  timestamp: '2025-09-19 07:43:01',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'd7e7ae47-6720-4ff6-b540-64ea1fa4eda9',
  processingTime: 731,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-19 07:43:01'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 734,
  userId: null,
  timestamp: '2025-09-19 07:43:01',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/d7e7ae47-6720-4ff6-b540-64ea1fa4eda9',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-19 07:43:02',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-19 07:44:56',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 50 models from openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:45:04'
}
{
  message: 'API key validated successfully with provider: openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:45:04'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'http:/...',
  provider: 'openrouter',
  providerName: 'OpenRouter',
  modelsDiscovered: 50,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '1e609386-b171-4d2d-8f40-f85c949ffb0f',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-19 07:45:04'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 1286,
  userId: null,
  timestamp: '2025-09-19 07:45:04',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 50 models from openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:45:25'
}
{
  message: 'API key validated successfully with provider: openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:45:25'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'http:/...',
  provider: 'openrouter',
  providerName: 'OpenRouter',
  modelsDiscovered: 50,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '3132b922-7dc7-487f-b0eb-1aadbc0d935f',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-19 07:45:25'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 1319,
  userId: null,
  timestamp: '2025-09-19 07:45:25',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:45:54'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:45:54'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'f5c5d1f6-a4eb-4c25-ad10-7c188724f312',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-19 07:45:54'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 238,
  userId: null,
  timestamp: '2025-09-19 07:45:54',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-19 07:46:02'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4b03ba4e-4d64-40ec-9088-3797cfb4c50c',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-19 07:46:02'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '4b03ba4e-4d64-40ec-9088-3797cfb4c50c',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-19 07:46:02'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a0d136bc-44fc-415f-ac33-e305e993aea4',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-19 07:46:02'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 720,
  error: null,
  timestamp: '2025-09-19 07:46:02',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4b03ba4e-4d64-40ec-9088-3797cfb4c50c',
  processingTime: 720,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-19 07:46:02'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 723,
  userId: null,
  timestamp: '2025-09-19 07:46:02',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/4b03ba4e-4d64-40ec-9088-3797cfb4c50c',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-19 07:46:02',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 07:48:14'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-19 07:48:14'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:14'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-19 07:48:14'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-19 07:48:14'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:19'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:816:11)\n' +
    '    at NativeConnection.openUri (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:120:9)\n' +
    '    at async Server.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:34:7)\n' +
    '    at async Server.start (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:739:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-19 07:48:19',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-19 07:48:19'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:19'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongodb\\lib\\sdam\\topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:594:17)\n' +
    '    at process.processTimers (node:internal/timers:529:7)',
  component: 'mongodb',
  timestamp: '2025-09-19 07:48:19',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:19'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:19'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:19'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:20'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 15960,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 07:48:20'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-19 07:48:53',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 50 models from openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:59'
}
{
  message: 'API key validated successfully with provider: openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:48:59'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'http:/...',
  provider: 'openrouter',
  providerName: 'OpenRouter',
  modelsDiscovered: 50,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '5c1175ab-e73d-4a81-a093-04f3ebb8a08c',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-19 07:48:59'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 1495,
  userId: null,
  timestamp: '2025-09-19 07:48:59',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:49:10'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 07:49:10'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '2419ffc5-a43a-4e9c-97db-3749c4977b0b',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-19 07:49:10'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 242,
  userId: null,
  timestamp: '2025-09-19 07:49:10',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-19 07:49:14'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4dff4587-569f-4dfa-97b2-d4b9d0f63a79',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-19 07:49:14'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '4dff4587-569f-4dfa-97b2-d4b9d0f63a79',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-19 07:49:14'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ce915285-db46-452d-b406-97658fa84934',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-19 07:49:14'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 387,
  error: null,
  timestamp: '2025-09-19 07:49:15',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4dff4587-569f-4dfa-97b2-d4b9d0f63a79',
  processingTime: 388,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-19 07:49:15'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 392,
  userId: null,
  timestamp: '2025-09-19 07:49:15',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/4dff4587-569f-4dfa-97b2-d4b9d0f63a79',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-19 07:49:15',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-19 07:50:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-19 07:50:55',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 08:14:35'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-19 08:14:35'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:14:36'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-19 08:14:36'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-19 08:14:36'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:14:41'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:816:11)\n' +
    '    at NativeConnection.openUri (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:120:9)\n' +
    '    at async Server.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:34:7)\n' +
    '    at async Server.start (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:739:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-19 08:14:41',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-19 08:14:41'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:14:41'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongodb\\lib\\sdam\\topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:594:17)\n' +
    '    at process.processTimers (node:internal/timers:529:7)',
  component: 'mongodb',
  timestamp: '2025-09-19 08:14:41',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:14:41'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:14:41'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:14:41'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:14:41'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 17248,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 08:14:41'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-19 08:15:51',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 08:44:03'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-19 08:44:03'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:44:03'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-19 08:44:03'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-19 08:44:03'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:44:08'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:816:11)\n' +
    '    at NativeConnection.openUri (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:120:9)\n' +
    '    at async Server.initialize (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:34:7)\n' +
    '    at async Server.start (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:739:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-19 08:44:08',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-19 08:44:08'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:44:08'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongodb\\lib\\sdam\\topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:594:17)\n' +
    '    at process.processTimers (node:internal/timers:529:7)',
  component: 'mongodb',
  timestamp: '2025-09-19 08:44:08',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:44:08'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:44:08'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:44:08'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:44:08'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 8216,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 08:44:08'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-19 08:46:08',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-19 08:47:23',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 08:58:38'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 10864,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 08:58:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 8,
  userId: null,
  timestamp: '2025-09-19 08:59:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-19 08:59:47',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:03:56'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 2648,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 09:03:56'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 7,
  userId: null,
  timestamp: '2025-09-19 09:04:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:07:53'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 17024,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 09:07:53'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-19 09:09:09',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-19 09:11:55'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 16240,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-19 09:11:55'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-19 09:12:50',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:18:40'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 2992,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-20 18:18:40'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-20 18:22:40',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:23:07'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 18:23:07'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '870193b6-342e-41d3-a32e-6fea6ee33750',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-20 18:23:07'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 265,
  userId: null,
  timestamp: '2025-09-20 18:23:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 18:23:11'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ca0c573a-fdf6-44de-8677-c635f93a315d',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 18:23:11'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'ca0c573a-fdf6-44de-8677-c635f93a315d',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 18:23:11'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '2b6771dc-aa67-4336-bbcf-79fe7aa53ba2',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-20 18:23:11'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 430,
  error: null,
  timestamp: '2025-09-20 18:23:12',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ca0c573a-fdf6-44de-8677-c635f93a315d',
  processingTime: 435,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-20 18:23:12'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 439,
  userId: null,
  timestamp: '2025-09-20 18:23:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/ca0c573a-fdf6-44de-8677-c635f93a315d',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-20 18:23:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 18:23:28'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '63cfca0b-d298-4554-8397-b57d35d05b12',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 18:23:28'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '63cfca0b-d298-4554-8397-b57d35d05b12',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 18:23:28'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'facef519-7e95-434f-96fa-d085a7a7e87d',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-20 18:23:28'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  responseLength: 3935,
  responseTime: 6324,
  error: null,
  timestamp: '2025-09-20 18:23:35',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '63cfca0b-d298-4554-8397-b57d35d05b12',
  processingTime: 6326,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-20 18:23:35'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 6328,
  userId: null,
  timestamp: '2025-09-20 18:23:35',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/63cfca0b-d298-4554-8397-b57d35d05b12',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-20 18:23:35',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 6,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 18:37:16'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '765a70b5-2ce1-4d66-aec7-1170e8b31c1e',
  query: 'ok thx',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 18:37:16'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '765a70b5-2ce1-4d66-aec7-1170e8b31c1e',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 18:37:16'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '0cb79efa-eccc-4edd-b68a-cdd40238c2c1',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-20 18:37:16'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  responseLength: 61,
  responseTime: 677,
  error: null,
  timestamp: '2025-09-20 18:37:17',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '765a70b5-2ce1-4d66-aec7-1170e8b31c1e',
  processingTime: 680,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-20 18:37:17'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 685,
  userId: null,
  timestamp: '2025-09-20 18:37:17',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/765a70b5-2ce1-4d66-aec7-1170e8b31c1e',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-20 18:37:17',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-20 19:04:23',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 19:04:38'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 19:04:38'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '40d98f7a-1510-4411-8ffa-7df276a183df',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-20 19:04:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 311,
  userId: null,
  timestamp: '2025-09-20 19:04:38',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-pro-002',
  models: [ 'gemini-1.5-pro-002' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 19:04:43'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '22bf70cd-7ccb-487a-8508-6e55c092d9a8',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 19:04:43'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-pro-002' ],
  taskId: '22bf70cd-7ccb-487a-8508-6e55c092d9a8',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 19:04:43'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '82b8db72-9da9-47ca-bb1f-742e9640375f',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-20 19:04:43'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 267,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-20 19:04:44',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '82b8db72-9da9-47ca-bb1f-742e9640375f',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '22bf70cd-7ccb-487a-8508-6e55c092d9a8',
  error: 'RATE_LIMIT',
  level: 'error',
  message: 'Direct processing failed',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'RATE_LIMIT',
  level: 'warn',
  message: 'Direct processing failed, falling back to queue',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '29538dc4-1c93-4225-b5dd-71689d0e9be1',
  queryLength: 50,
  hasFiles: false,
  options: {
    selectedModel: 'gemini-1.5-pro-002',
    selectedModels: [ 'gemini-1.5-pro-002' ],
    conversationId: 'conv_1758391483566_8kuhxy42n',
    fileIds: [],
    workspaceId: 'default',
    priority: 0,
    skipCache: false,
    enhanceWithKnowledge: true,
    enableLearning: true
  },
  level: 'info',
  message: 'New query submitted',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '23',
  requestId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0',
  priority: 0,
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Query job added to queue',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '23',
  requestId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '060507d6-1484-4d18-badd-be7e04151386',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/v1/queries',
  statusCode: 202,
  responseTime: 41,
  userId: null,
  timestamp: '2025-09-20 19:04:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '3cb25849-15d8-480e-834b-fb2a15cd8d3e',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 332,
  userId: null,
  timestamp: '2025-09-20 19:04:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 93,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-20 19:04:44',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '3cb25849-15d8-480e-834b-fb2a15cd8d3e',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '060507d6-1484-4d18-badd-be7e04151386',
  totalTime: 102,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '060507d6-1484-4d18-badd-be7e04151386',
  timestamp: '2025-09-20 19:04:44',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '23',
  timestamp: '2025-09-20 19:04:44',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '23',
  jobType: 'processQuery',
  attempts: 1,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758391483566_8kuhxy42n',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '29538dc4-1c93-4225-b5dd-71689d0e9be1'
    },
    requestId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0'
  },
  timestamp: '2025-09-20 19:04:44',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '9e85944b-2287-4dbd-b871-0197743d7ac2',
  queryId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0',
  level: 'info',
  message: 'Query result requested',
  timestamp: '2025-09-20 19:04:44'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/queries/0ae33ac1-b3da-492b-9331-68d1fa774ad0',
  statusCode: 404,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-20 19:04:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/0ae33ac1-b3da-492b-9331-68d1fa774ad0',
  statusCode: 200,
  responseTime: 10,
  userId: null,
  timestamp: '2025-09-20 19:04:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '23',
  requestId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-20 19:04:46'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'da43a85d-7223-4606-adf0-ec492268c027',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-20 19:04:46'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'b7a4b116-975b-4ab3-8e3c-840f4b13c597',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-20 19:04:46'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 86,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-20 19:04:46',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'b7a4b116-975b-4ab3-8e3c-840f4b13c597',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-20 19:04:46'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'da43a85d-7223-4606-adf0-ec492268c027',
  totalTime: 89,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-20 19:04:46'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: 'da43a85d-7223-4606-adf0-ec492268c027',
  timestamp: '2025-09-20 19:04:46',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '23',
  timestamp: '2025-09-20 19:04:46',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '23',
  jobType: 'processQuery',
  attempts: 2,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758391483566_8kuhxy42n',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '29538dc4-1c93-4225-b5dd-71689d0e9be1'
    },
    requestId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0'
  },
  timestamp: '2025-09-20 19:04:46',
  level: 'error'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 19:04:49'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-20 19:04:49'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '197918f8-7d76-4768-8536-8700a8f708a4',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-20 19:04:49'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 67,
  userId: null,
  timestamp: '2025-09-20 19:04:49',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '23',
  requestId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-20 19:04:52'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '661a7d06-2ba6-4825-b2dc-c267f99ff279',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-20 19:04:52'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '01f1a14c-5ffb-4cdb-b1b8-f29ec338efe4',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-20 19:04:52'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 85,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-20 19:04:52',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '01f1a14c-5ffb-4cdb-b1b8-f29ec338efe4',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-20 19:04:52'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '661a7d06-2ba6-4825-b2dc-c267f99ff279',
  totalTime: 89,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-20 19:04:52'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '661a7d06-2ba6-4825-b2dc-c267f99ff279',
  timestamp: '2025-09-20 19:04:52',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '23',
  timestamp: '2025-09-20 19:04:52',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '23',
  jobType: 'processQuery',
  attempts: 3,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758391483566_8kuhxy42n',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '29538dc4-1c93-4225-b5dd-71689d0e9be1'
    },
    requestId: '0ae33ac1-b3da-492b-9331-68d1fa774ad0'
  },
  timestamp: '2025-09-20 19:04:52',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 19:04:56'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3227b33b-719b-401c-b701-0c89b82a43c5',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 19:04:56'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '3227b33b-719b-401c-b701-0c89b82a43c5',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 19:04:56'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ad857843-64cd-4a07-8193-397f142c18c0',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-20 19:04:56'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 633,
  error: null,
  timestamp: '2025-09-20 19:04:57',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3227b33b-719b-401c-b701-0c89b82a43c5',
  processingTime: 636,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-20 19:04:57'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 639,
  userId: null,
  timestamp: '2025-09-20 19:04:57',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/3227b33b-719b-401c-b701-0c89b82a43c5',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-20 19:04:57',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 19:05:01'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'd868ab98-07b1-4b62-8f53-5f74aa1608b6',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 19:05:01'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'd868ab98-07b1-4b62-8f53-5f74aa1608b6',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 19:05:01'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '24414a90-1690-4f28-b258-4f0b1d9747c8',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-20 19:05:01'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  responseLength: 3791,
  responseTime: 5978,
  error: null,
  timestamp: '2025-09-20 19:05:07',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'd868ab98-07b1-4b62-8f53-5f74aa1608b6',
  processingTime: 5980,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-20 19:05:07'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 5983,
  userId: null,
  timestamp: '2025-09-20 19:05:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/d868ab98-07b1-4b62-8f53-5f74aa1608b6',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-20 19:05:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-20 19:21:00',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-2.5-pro',
  models: [ 'gemini-2.5-pro' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 19:27:33'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'c286c5a1-db3f-4c13-a3cf-7b692c7aae58',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 19:27:33'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-2.5-pro' ],
  taskId: 'c286c5a1-db3f-4c13-a3cf-7b692c7aae58',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 19:27:33'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '40ed0831-de8f-4b86-8dc7-f2d2cb35d960',
  modelId: 'gemini-2.5-pro',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-20 19:27:33'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 36,
  responseLength: 5,
  responseTime: 9507,
  error: null,
  timestamp: '2025-09-20 19:27:42',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'c286c5a1-db3f-4c13-a3cf-7b692c7aae58',
  processingTime: 9510,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-20 19:27:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 9513,
  userId: null,
  timestamp: '2025-09-20 19:27:42',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/c286c5a1-db3f-4c13-a3cf-7b692c7aae58',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-20 19:27:42',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-2.5-pro',
  models: [ 'gemini-2.5-pro' ],
  messageLength: 55,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-20 19:28:25'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'a0bb1380-9f5e-405d-8059-f2a57a75b27d',
  query: 'give me the best sensitivity for free fire in iphone 13',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-20 19:28:25'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-2.5-pro' ],
  taskId: 'a0bb1380-9f5e-405d-8059-f2a57a75b27d',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-20 19:28:25'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'da044bf3-db7d-42e8-ba25-0b9f5190fc21',
  modelId: 'gemini-2.5-pro',
  promptLength: 55,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-20 19:28:25'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 55,
  responseLength: 5273,
  responseTime: 27750,
  error: null,
  timestamp: '2025-09-20 19:28:52',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'a0bb1380-9f5e-405d-8059-f2a57a75b27d',
  processingTime: 27753,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-20 19:28:52'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 27755,
  userId: null,
  timestamp: '2025-09-20 19:28:52',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/a0bb1380-9f5e-405d-8059-f2a57a75b27d',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-20 19:28:53',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:08:47'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 5172,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-21 07:08:47'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-21 07:10:08',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:10:24'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:10:24'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'fe01653c-b2c1-410d-98dd-893a307e2cc8',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-21 07:10:24'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 245,
  userId: null,
  timestamp: '2025-09-21 07:10:24',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-2.5-pro',
  models: [ 'gemini-2.5-pro' ],
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-21 07:10:38'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '271a32e6-a311-4a02-ad8c-43dad56f610f',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-21 07:10:38'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-2.5-pro' ],
  taskId: '271a32e6-a311-4a02-ad8c-43dad56f610f',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-21 07:10:38'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '313699cc-c833-4215-8de3-c4ba40267ee5',
  modelId: 'gemini-2.5-pro',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-21 07:10:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 2,
  responseLength: 32,
  responseTime: 7428,
  error: null,
  timestamp: '2025-09-21 07:10:46',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '271a32e6-a311-4a02-ad8c-43dad56f610f',
  processingTime: 7430,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-21 07:10:46'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 7434,
  userId: null,
  timestamp: '2025-09-21 07:10:46',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/271a32e6-a311-4a02-ad8c-43dad56f610f',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-21 07:10:46',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 07:21:41'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 11216,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-21 07:21:41'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-21 11:16:33'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-21 11:16:33'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:16:33'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-21 11:16:33'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-21 11:16:33'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:16:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:816:11)\n' +
    '    at NativeConnection.openUri (C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongoose\\lib\\connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\database.js:120:9)\n' +
    '    at async Server.initialize (C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:34:7)\n' +
    '    at async Server.start (C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\api\\server.js:739:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-21 11:16:38',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-21 11:16:38'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:16:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\mongodb\\lib\\sdam\\topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:594:17)\n' +
    '    at process.processTimers (node:internal/timers:529:7)',
  component: 'mongodb',
  timestamp: '2025-09-21 11:16:38',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:16:38'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:16:38'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:16:38'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:16:38'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 15732,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-21 11:16:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 12,
  userId: null,
  timestamp: '2025-09-21 11:19:14',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:19:30'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 11:19:30'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '252868c3-10bd-4042-83c7-c5228f68f424',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-21 11:19:30'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 522,
  userId: null,
  timestamp: '2025-09-21 11:19:30',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-21 11:19:42'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b73be3f3-e998-48ed-b170-66fb11aca57c',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-21 11:19:42'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'b73be3f3-e998-48ed-b170-66fb11aca57c',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-21 11:19:42'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'e4336fda-fe9b-4f89-9a1d-e46fef4b6a28',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-21 11:19:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 36,
  responseTime: 565,
  error: null,
  timestamp: '2025-09-21 11:19:42',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b73be3f3-e998-48ed-b170-66fb11aca57c',
  processingTime: 567,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-21 11:19:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 570,
  userId: null,
  timestamp: '2025-09-21 11:19:42',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/b73be3f3-e998-48ed-b170-66fb11aca57c',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-21 11:19:43',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-21 11:27:06',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-21 11:28:09',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 13:25:17'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 12272,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-21 13:25:17'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-21 13:27:58',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-21 13:30:35',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:15:37'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 3104,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-21 18:15:37'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-21 18:17:11',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:29:38'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:29:38'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '27858557-816a-43ef-b534-3d12d24c8c78',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-21 18:29:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 460,
  userId: null,
  timestamp: '2025-09-21 18:29:38',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-pro-002',
  models: [
    'gemini-1.5-pro-002',
    'gemini-1.5-pro',
    'gemini-1.5-flash',
    'gemini-1.5-flash-002',
    'gemini-2.5-pro'
  ],
  messageLength: 39,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'cf3f87e3-7629-4460-8c7d-2607dc9cb02d',
  query: 'Write me a short story about the future',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  models: [
    'gemini-1.5-pro-002',
    'gemini-1.5-pro',
    'gemini-1.5-flash',
    'gemini-1.5-flash-002',
    'gemini-2.5-pro'
  ],
  taskId: 'cf3f87e3-7629-4460-8c7d-2607dc9cb02d',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'dfb1619a-d092-4473-ba4e-a3031f8dabc7',
  modelsCount: 5,
  selectedModels: [
    'gemini-1.5-pro-002',
    'gemini-1.5-pro',
    'gemini-1.5-flash',
    'gemini-1.5-flash-002',
    'gemini-2.5-pro'
  ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '70441684-4de6-4d6b-9bb1-2a3e4cfa5537',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 39,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'f3e6b1f6-a981-4b2f-b024-a4eabe3d9b89',
  modelId: 'gemini-1.5-pro',
  promptLength: 39,
  level: 'info',
  message: 'Calling model gemini-1.5-pro',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '89f199aa-11cd-4b15-a248-a8a2c97b1dbd',
  modelId: 'gemini-1.5-flash',
  promptLength: 39,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'f0504b97-d152-4873-9847-9733006292a0',
  modelId: 'gemini-1.5-flash-002',
  promptLength: 39,
  level: 'info',
  message: 'Calling model gemini-1.5-flash-002',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'b975fb37-81bc-4cdd-9eb7-f6025c3a8efc',
  modelId: 'gemini-2.5-pro',
  promptLength: 39,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-21 18:29:49'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 39,
  responseLength: 0,
  responseTime: 776,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-21 18:29:50',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '70441684-4de6-4d6b-9bb1-2a3e4cfa5537',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-21 18:29:50'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro',
  promptLength: 39,
  responseLength: 0,
  responseTime: 979,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-21 18:29:50',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'f3e6b1f6-a981-4b2f-b024-a4eabe3d9b89',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro, retry after 60s',
  timestamp: '2025-09-21 18:29:50'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash-002',
  promptLength: 39,
  responseLength: 2556,
  responseTime: 4855,
  error: null,
  timestamp: '2025-09-21 18:29:54',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 39,
  responseLength: 2556,
  responseTime: 5293,
  error: null,
  timestamp: '2025-09-21 18:29:54',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 39,
  responseLength: 0,
  responseTime: 30007,
  error: 'timeout of 30000ms exceeded',
  timestamp: '2025-09-21 18:30:19',
  level: 'info',
  message: 'Model Call'
}
{
  message: 'Retrying gemini-2.5-pro in 1000ms (attempt 1/3)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:30:19'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'c2766638-7e41-49b5-a12f-4eedb5bad13c',
  modelId: 'gemini-2.5-pro',
  promptLength: 39,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-21 18:30:20'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 39,
  responseLength: 0,
  responseTime: 30009,
  error: 'timeout of 30000ms exceeded',
  timestamp: '2025-09-21 18:30:50',
  level: 'info',
  message: 'Model Call'
}
{
  message: 'Retrying gemini-2.5-pro in 2000ms (attempt 2/3)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:30:50'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '63976085-7446-4b27-8d7f-6fcd1aaa1514',
  modelId: 'gemini-2.5-pro',
  promptLength: 39,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-21 18:30:52'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 39,
  responseLength: 4449,
  responseTime: 26753,
  error: null,
  timestamp: '2025-09-21 18:31:19',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'dfb1619a-d092-4473-ba4e-a3031f8dabc7',
  totalTime: 89809,
  successful: 3,
  failed: 2,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-21 18:31:19'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'cf3f87e3-7629-4460-8c7d-2607dc9cb02d',
  processingTime: 89863,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-21 18:31:19'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 89867,
  userId: null,
  timestamp: '2025-09-21 18:31:19',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/cf3f87e3-7629-4460-8c7d-2607dc9cb02d',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-21 18:31:20',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-pro-002',
  models: [
    'gemini-1.5-pro-002',
    'gemini-1.5-pro',
    'gemini-1.5-flash',
    'gemini-1.5-flash-002',
    'gemini-2.5-pro'
  ],
  messageLength: 6,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '600eb05e-89eb-42fd-8b52-2373ec0b1c3d',
  query: 'ok thx',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  models: [
    'gemini-1.5-pro-002',
    'gemini-1.5-pro',
    'gemini-1.5-flash',
    'gemini-1.5-flash-002',
    'gemini-2.5-pro'
  ],
  taskId: '600eb05e-89eb-42fd-8b52-2373ec0b1c3d',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'ef2e51e0-3b15-40e4-ac95-502fe802f273',
  modelsCount: 5,
  selectedModels: [
    'gemini-1.5-pro-002',
    'gemini-1.5-pro',
    'gemini-1.5-flash',
    'gemini-1.5-flash-002',
    'gemini-2.5-pro'
  ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'fc77e018-5676-4a3a-8391-62b5c2989214',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '8f56a5df-d357-4af6-96b7-acd3559d1451',
  modelId: 'gemini-1.5-pro',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-1.5-pro',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '70907a50-2f9d-4558-bab9-568b96ae8c67',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '0aa658c5-5d88-4226-aecc-e455b8a27ac5',
  modelId: 'gemini-1.5-flash-002',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-1.5-flash-002',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a43acfc3-0174-49aa-a672-88cc6f14805e',
  modelId: 'gemini-2.5-pro',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro',
  promptLength: 6,
  responseLength: 0,
  responseTime: 250,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-21 18:32:37',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '8f56a5df-d357-4af6-96b7-acd3559d1451',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro, retry after 60s',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 6,
  responseLength: 0,
  responseTime: 267,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-21 18:32:37',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'fc77e018-5676-4a3a-8391-62b5c2989214',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-21 18:32:37'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  responseLength: 60,
  responseTime: 628,
  error: null,
  timestamp: '2025-09-21 18:32:37',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash-002',
  promptLength: 6,
  responseLength: 60,
  responseTime: 771,
  error: null,
  timestamp: '2025-09-21 18:32:38',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 6,
  responseLength: 59,
  responseTime: 12887,
  error: null,
  timestamp: '2025-09-21 18:32:50',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'ef2e51e0-3b15-40e4-ac95-502fe802f273',
  totalTime: 12896,
  successful: 3,
  failed: 2,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-21 18:32:50'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '600eb05e-89eb-42fd-8b52-2373ec0b1c3d',
  processingTime: 12899,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-21 18:32:50'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 12901,
  userId: null,
  timestamp: '2025-09-21 18:32:50',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/600eb05e-89eb-42fd-8b52-2373ec0b1c3d',
  statusCode: 200,
  responseTime: 0,
  userId: null,
  timestamp: '2025-09-21 18:32:50',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-21 18:47:18',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 50 models from openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:47:26'
}
{
  message: 'API key validated successfully with provider: openrouter',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:47:26'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: "'best ...",
  provider: 'openrouter',
  providerName: 'OpenRouter',
  modelsDiscovered: 50,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'f509f343-0050-40ea-a618-83be553f27a9',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-21 18:47:26'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 1569,
  userId: null,
  timestamp: '2025-09-21 18:47:26',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:47:46'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-21 18:47:46'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '991d1cba-eadf-4276-8d17-cb8234b4f3e2',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-21 18:47:46'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 291,
  userId: null,
  timestamp: '2025-09-21 18:47:46',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-pro-002',
  models: [ 'gemini-1.5-pro-002', 'gemini-1.5-flash', 'gemini-2.5-pro' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '2f457ccf-7031-4b54-a2dc-ee20098f8e0f',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-pro-002', 'gemini-1.5-flash', 'gemini-2.5-pro' ],
  taskId: '2f457ccf-7031-4b54-a2dc-ee20098f8e0f',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '965c146e-7729-41a9-9b56-e233f76fa66e',
  modelsCount: 3,
  selectedModels: [ 'gemini-1.5-pro-002', 'gemini-1.5-flash', 'gemini-2.5-pro' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '9d3af8f7-9971-47f0-ae9b-226acc3ea359',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'c23a5949-8e82-49e8-b78b-15b8ae5e9a7f',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '1f95634d-0700-4e5f-85d2-7b271dbe4ca2',
  modelId: 'gemini-2.5-pro',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-2.5-pro',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 245,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-21 18:48:06',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '9d3af8f7-9971-47f0-ae9b-226acc3ea359',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-21 18:48:06'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  responseLength: 4412,
  responseTime: 6779,
  error: null,
  timestamp: '2025-09-21 18:48:13',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-2.5-pro',
  promptLength: 50,
  responseLength: 6707,
  responseTime: 29059,
  error: null,
  timestamp: '2025-09-21 18:48:35',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '965c146e-7729-41a9-9b56-e233f76fa66e',
  totalTime: 29067,
  successful: 2,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-21 18:48:35'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '2f457ccf-7031-4b54-a2dc-ee20098f8e0f',
  processingTime: 29122,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-21 18:48:35'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 29124,
  userId: null,
  timestamp: '2025-09-21 18:48:35',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/2f457ccf-7031-4b54-a2dc-ee20098f8e0f',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-21 18:48:35',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-21 18:54:27',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\Final project\\neuroXopenhandsXhaggingface---Cpy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:25:43'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 7068,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-22 13:25:43'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-22 13:31:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-22 13:34:25',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:34:39'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-22 13:34:39'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '4625004f-2aa0-402e-82ed-89a850d17e41',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-22 13:34:39'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 381,
  userId: null,
  timestamp: '2025-09-22 13:34:39',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-22 13:34:54'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '1a282345-986e-4029-8ec1-5a2561097ea7',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-22 13:34:54'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '1a282345-986e-4029-8ec1-5a2561097ea7',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-22 13:34:54'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'd24092c2-e3e2-4fdc-a6ed-5137045f553d',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-22 13:34:54'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  responseLength: 4482,
  responseTime: 7310,
  error: null,
  timestamp: '2025-09-22 13:35:01',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '1a282345-986e-4029-8ec1-5a2561097ea7',
  processingTime: 7313,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-22 13:35:01'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 7319,
  userId: null,
  timestamp: '2025-09-22 13:35:01',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/1a282345-986e-4029-8ec1-5a2561097ea7',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-22 13:35:02',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-22 13:35:16'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'c525d2b5-fe3f-4bdc-bb1e-b342496cca8f',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-22 13:35:16'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'c525d2b5-fe3f-4bdc-bb1e-b342496cca8f',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-22 13:35:16'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ce6e78ce-6e39-4580-a23d-456559f0a00d',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-22 13:35:16'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 36,
  responseTime: 677,
  error: null,
  timestamp: '2025-09-22 13:35:17',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'c525d2b5-fe3f-4bdc-bb1e-b342496cca8f',
  processingTime: 681,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-22 13:35:17'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 686,
  userId: null,
  timestamp: '2025-09-22 13:35:17',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/c525d2b5-fe3f-4bdc-bb1e-b342496cca8f',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-22 13:35:17',
  level: 'info',
  message: 'API Call'
}
