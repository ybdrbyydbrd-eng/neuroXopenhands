{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-05 13:25:36'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:37'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-05 13:25:37'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-05 13:25:37'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:816:11)\n' +
    '    at NativeConnection.openUri (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:120:9)\n' +
    '    at async Server.initialize (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:33:7)\n' +
    '    at async Server.start (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:658:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-05 13:25:42',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (/home/user/webapp/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongodb/lib/sdam/topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:581:17)\n' +
    '    at process.processTimers (node:internal/timers:519:7)',
  component: 'mongodb',
  timestamp: '2025-09-05 13:25:42',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 2665,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-05 13:25:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-05 13:26:36',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: '/home/user/webapp/7-main/new-main/neurochat/workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-05 19:30:19'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection error (suppressing further errors)',
  timestamp: '2025-09-05 19:30:19'
}
{
  message: 'Redis connection failed after 3 attempts, disabling Redis',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:20'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed',
  timestamp: '2025-09-05 19:30:20'
}
{
  service: 'enhanced-ai-pipeline',
  error: '',
  level: 'warn',
  message: 'Redis connection failed, continuing without Redis cache',
  timestamp: '2025-09-05 19:30:20'
}
{
  message: 'MongoDB disconnected',
  level: 'warn',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at _handleConnectionErrors (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:816:11)\n' +
    '    at NativeConnection.openUri (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongoose/lib/connection.js:791:11)\n' +
    '    at async DatabaseManager.connectMongoDB (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:91:30)\n' +
    '    at async DatabaseManager.initialize (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/utils/database.js:120:9)\n' +
    '    at async Server.initialize (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:34:7)\n' +
    '    at async Server.start (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/src/api/server.js:677:7)',
  component: 'mongodb',
  operation: 'connect',
  timestamp: '2025-09-05 19:30:25',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  level: 'warn',
  message: 'MongoDB connection failed, continuing without MongoDB',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017',
  stack: 'MongoServerSelectionError: connect ECONNREFUSED ::1:27017, connect ECONNREFUSED 127.0.0.1:27017\n' +
    '    at Timeout._onTimeout (/home/user/webapp/7-main/new-main/neurochat/backend/enhanced-ai-pipeline/node_modules/mongodb/lib/sdam/topology.js:278:38)\n' +
    '    at listOnTimeout (node:internal/timers:581:17)\n' +
    '    at process.processTimers (node:internal/timers:519:7)',
  component: 'mongodb',
  timestamp: '2025-09-05 19:30:25',
  level: 'error'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 4120,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-05 19:30:25'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\New folder\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 18:46:24'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 6884,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-15 18:46:24'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-15 18:46:34',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/favicon.ico',
  statusCode: 404,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-15 18:46:34',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-15 18:46:50',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: "C:\\Users\\Administrator\\Desktop\\YH's projet\\NeuroXopenhands\\neurochat\\neurochat\\workspaces",
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-15 21:18:23'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 4620,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-15 21:18:23'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-15 21:18:38',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/favicon.ico',
  statusCode: 404,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-15 21:18:38',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 3,
  userId: null,
  timestamp: '2025-09-15 21:19:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: "C:\\Users\\Administrator\\Desktop\\YH's projet\\NeuroXopenhands\\neurochat\\neurochat\\workspaces",
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-16 11:51:04'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 4324,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-16 11:51:04'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 8,
  userId: null,
  timestamp: '2025-09-16 11:51:10',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-16 11:52:59',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 17:49:30'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 18868,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 17:49:30'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 10,
  userId: null,
  timestamp: '2025-09-17 17:49:34',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 9,
  userId: null,
  timestamp: '2025-09-17 18:41:20',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:34'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 21:14:35'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 10120,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 21:14:35'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 8,
  userId: null,
  timestamp: '2025-09-17 21:14:39',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:05:14'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 13732,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 22:05:14'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 12,
  userId: null,
  timestamp: '2025-09-17 22:05:24',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:06:03'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '8b7201f1-2b25-4092-9c73-faff4b6db8ea',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-17 22:06:03'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 315,
  userId: null,
  timestamp: '2025-09-17 22:06:03',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:20:41'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 14824,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 22:20:41'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 40,
  userId: null,
  timestamp: '2025-09-17 22:20:48',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:21:12'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'fe80cbf8-613e-4a5a-864e-0458f0d1db14',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-17 22:21:12'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 362,
  userId: null,
  timestamp: '2025-09-17 22:21:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:51:38'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 17292,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-17 22:51:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 12,
  userId: null,
  timestamp: '2025-09-17 22:51:44',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  status: 401,
  level: 'warn',
  message: 'Authentication failed for openai',
  timestamp: '2025-09-17 22:52:05'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-17 22:52:05'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: '76c9f61e-3e95-4c5b-9f9d-b31ef5ef3f62',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-17 22:52:05'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 1768,
  userId: null,
  timestamp: '2025-09-17 22:52:05',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-17 23:26:03',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:31:15'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 19388,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-18 18:31:15'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-18 18:31:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 21,
  userId: null,
  timestamp: '2025-09-18 18:35:07',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3a65dddc-60a1-472b-9951-ec1178de75c2',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '3a65dddc-60a1-472b-9951-ec1178de75c2',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'c9554eeb-1706-4175-a56d-262b693305db',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 0,
  responseTime: 1,
  error: 'No API key available for provider: google',
  timestamp: '2025-09-18 18:35:18',
  level: 'info',
  message: 'Model Call'
}
{
  message: 'Retrying gemini-1.5-flash in 1000ms (attempt 1/3)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:35:18'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '41608ebe-288b-4d70-aab6-69f6b8708d26',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:35:19'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 0,
  responseTime: 1,
  error: 'No API key available for provider: google',
  timestamp: '2025-09-18 18:35:19',
  level: 'info',
  message: 'Model Call'
}
{
  message: 'Retrying gemini-1.5-flash in 2000ms (attempt 2/3)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:35:19'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '9fccef23-c379-4c40-851f-24af87715e9a',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 0,
  responseTime: 0,
  error: 'No API key available for provider: google',
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '3a65dddc-60a1-472b-9951-ec1178de75c2',
  error: 'NETWORK_ERROR',
  level: 'error',
  message: 'Direct processing failed',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'NETWORK_ERROR',
  level: 'warn',
  message: 'Direct processing failed, falling back to queue',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e',
  queryLength: 2,
  hasFiles: false,
  options: {
    selectedModel: 'gemini-1.5-flash',
    selectedModels: [ 'gemini-1.5-flash' ],
    conversationId: 'assistant_1758216918942',
    workspaceId: 'default',
    priority: 0,
    skipCache: false,
    enhanceWithKnowledge: true,
    enableLearning: true
  },
  level: 'info',
  message: 'New query submitted',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  priority: 0,
  query: 'hi',
  level: 'info',
  message: 'Query job added to queue',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  query: 'hi',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '09827f6f-441a-4933-b53d-d6cf9cd7e1a9',
  timestamp: '2025-09-18 18:35:22',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '21',
  timestamp: '2025-09-18 18:35:22',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/v1/queries',
  statusCode: 202,
  responseTime: 15,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '21',
  jobType: 'processQuery',
  attempts: 1,
  data: {
    query: 'hi',
    options: {
      selectedModel: 'gemini-1.5-flash',
      selectedModels: [ 'gemini-1.5-flash' ],
      conversationId: 'assistant_1758216918942',
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e'
    },
    requestId: '3975a11e-838b-4945-a150-631825f20e77'
  },
  timestamp: '2025-09-18 18:35:22',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 3062,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '36f2d860-5959-40ff-b26c-cbbaaba25586',
  queryId: '3975a11e-838b-4945-a150-631825f20e77',
  level: 'info',
  message: 'Query result requested',
  timestamp: '2025-09-18 18:35:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/queries/3975a11e-838b-4945-a150-631825f20e77',
  statusCode: 404,
  responseTime: 4,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/3975a11e-838b-4945-a150-631825f20e77',
  statusCode: 200,
  responseTime: 7,
  userId: null,
  timestamp: '2025-09-18 18:35:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  query: 'hi',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:35:24'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '0ac082ed-a976-4ab6-b66c-d3a5cef5145f',
  timestamp: '2025-09-18 18:35:24',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '21',
  timestamp: '2025-09-18 18:35:24',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '21',
  jobType: 'processQuery',
  attempts: 2,
  data: {
    query: 'hi',
    options: {
      selectedModel: 'gemini-1.5-flash',
      selectedModels: [ 'gemini-1.5-flash' ],
      conversationId: 'assistant_1758216918942',
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e'
    },
    requestId: '3975a11e-838b-4945-a150-631825f20e77'
  },
  timestamp: '2025-09-18 18:35:24',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '21',
  requestId: '3975a11e-838b-4945-a150-631825f20e77',
  query: 'hi',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:35:30'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '97531f11-3854-415a-b7b2-94f2b2394990',
  timestamp: '2025-09-18 18:35:30',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '21',
  timestamp: '2025-09-18 18:35:30',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error No matching models found for the provided selection',
  stack: 'Error: No matching models found for the provided selection\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:446:17)\n' +
    '    at QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:55)\n' +
    '    at Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:25)\n' +
    '    at handlers.<computed> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:733:42)\n' +
    '    at Queue.processJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\node_modules\\bull\\lib\\queue.js:1210:22)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '21',
  jobType: 'processQuery',
  attempts: 3,
  data: {
    query: 'hi',
    options: {
      selectedModel: 'gemini-1.5-flash',
      selectedModels: [ 'gemini-1.5-flash' ],
      conversationId: 'assistant_1758216918942',
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: 'c0f99aea-a56e-4e9e-a48c-825fcefaef2e'
    },
    requestId: '3975a11e-838b-4945-a150-631825f20e77'
  },
  timestamp: '2025-09-18 18:35:30',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:38:41',
  level: 'info',
  message: 'API Call'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:40:57'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:40:57'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'f1db990f-b44b-4b37-84d8-389f2aad6250',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-18 18:40:57'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 331,
  userId: null,
  timestamp: '2025-09-18 18:40:57',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '1b38b68d-82f2-4a0e-a8a3-c6b63a147140',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:00'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 954,
  error: null,
  timestamp: '2025-09-18 18:41:01',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  processingTime: 956,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:41:01'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 960,
  userId: null,
  timestamp: '2025-09-18 18:41:01',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/4e6cf567-8626-4932-a9dc-0c7ad16c6687',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:41:01',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 8,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b0e7df2d-b08b-4734-a943-7889b133a54b',
  query: 'hi there',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'b0e7df2d-b08b-4734-a943-7889b133a54b',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'd0d14a6e-1271-4360-94b1-b45587af8ba8',
  modelId: 'gemini-1.5-flash',
  promptLength: 8,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:08'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 8,
  responseLength: 36,
  responseTime: 664,
  error: null,
  timestamp: '2025-09-18 18:41:09',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b0e7df2d-b08b-4734-a943-7889b133a54b',
  processingTime: 665,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:41:09'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 667,
  userId: null,
  timestamp: '2025-09-18 18:41:09',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/b0e7df2d-b08b-4734-a943-7889b133a54b',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:41:09',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '8364e70a-e120-47c9-98f4-1795c5b18678',
  query: 'hi',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '8364e70a-e120-47c9-98f4-1795c5b18678',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a6a1eac8-999b-4240-8147-2365163468b6',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 36,
  responseTime: 489,
  error: null,
  timestamp: '2025-09-18 18:41:18',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '8364e70a-e120-47c9-98f4-1795c5b18678',
  processingTime: 490,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:41:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 493,
  userId: null,
  timestamp: '2025-09-18 18:41:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/8364e70a-e120-47c9-98f4-1795c5b18678',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:41:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 81,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  query: 'hi can you help me to find the best ai models for coding , my budjet is 20 dollar',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '29b578ae-adb8-496a-86da-e54ce4f31a4e',
  modelId: 'gemini-1.5-flash',
  promptLength: 81,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:41:56'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 81,
  responseLength: 2221,
  responseTime: 3715,
  error: null,
  timestamp: '2025-09-18 18:42:00',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  processingTime: 3716,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:42:00'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 3718,
  userId: null,
  timestamp: '2025-09-18 18:42:00',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/ea81ad76-b85f-4e60-83a2-6bc0ba2fe265',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:42:00',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 48,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  query: 'next time answer with the name of the model only',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '2f4d1a16-c36d-4c97-af86-98df7d9342eb',
  modelId: 'gemini-1.5-flash',
  promptLength: 48,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 48,
  responseLength: 5,
  responseTime: 503,
  error: null,
  timestamp: '2025-09-18 18:42:28',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  processingTime: 505,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:42:28'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 507,
  userId: null,
  timestamp: '2025-09-18 18:42:28',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/b1e1c7cd-3e31-4fe8-8186-756a61a989a9',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:42:28',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 32,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  query: 'ok now what is the models again?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ff82b732-26f5-493e-90ad-c25227092b19',
  modelId: 'gemini-1.5-flash',
  promptLength: 32,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:42:48'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 32,
  responseLength: 245,
  responseTime: 845,
  error: null,
  timestamp: '2025-09-18 18:42:49',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  processingTime: 849,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:42:49'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 852,
  userId: null,
  timestamp: '2025-09-18 18:42:49',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/edc68bf7-5f2c-4b57-a22d-92b8de2c6d78',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:42:49',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 2,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  query: 'ok',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'dccef9d0-73d0-4a6e-a543-6ee78557cccf',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:43:21'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 2,
  responseLength: 33,
  responseTime: 504,
  error: null,
  timestamp: '2025-09-18 18:43:22',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  processingTime: 505,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:43:22'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 507,
  userId: null,
  timestamp: '2025-09-18 18:43:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/22b835ce-8b1a-4f12-a9ec-60ba64df9048',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:43:22',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 6,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  query: 'no thx',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a237c5c5-b1c2-4741-a610-80b03609b926',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:43:31'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 6,
  responseLength: 51,
  responseTime: 576,
  error: null,
  timestamp: '2025-09-18 18:43:32',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  processingTime: 578,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:43:32'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 580,
  userId: null,
  timestamp: '2025-09-18 18:43:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/eb30a177-ce64-4849-8492-e5cdb1ffa8c0',
  statusCode: 200,
  responseTime: 0,
  userId: null,
  timestamp: '2025-09-18 18:43:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 30,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '558d928c-529b-4704-9522-c06c55263916',
  query: 'what is the time now in london',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '558d928c-529b-4704-9522-c06c55263916',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '023a1674-f1fa-41ee-84b1-65bb825a4a54',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:43:57'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  responseLength: 233,
  responseTime: 917,
  error: null,
  timestamp: '2025-09-18 18:43:58',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '558d928c-529b-4704-9522-c06c55263916',
  processingTime: 919,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:43:58'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 921,
  userId: null,
  timestamp: '2025-09-18 18:43:58',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/558d928c-529b-4704-9522-c06c55263916',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:43:58',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 19,
  userId: null,
  timestamp: '2025-09-18 18:44:10',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:47:19',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-pro-002',
  models: [ 'gemini-1.5-pro-002' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '21b766f3-ba88-49fb-be7f-1c58c4cb7bc1',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-pro-002' ],
  taskId: '21b766f3-ba88-49fb-be7f-1c58c4cb7bc1',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ad761492-ce1d-4625-b269-dc576fdcdab1',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 281,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'ad761492-ce1d-4625-b269-dc576fdcdab1',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '21b766f3-ba88-49fb-be7f-1c58c4cb7bc1',
  error: 'RATE_LIMIT',
  level: 'error',
  message: 'Direct processing failed',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  error: 'RATE_LIMIT',
  level: 'warn',
  message: 'Direct processing failed, falling back to queue',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a',
  queryLength: 50,
  hasFiles: false,
  options: {
    selectedModel: 'gemini-1.5-pro-002',
    selectedModels: [ 'gemini-1.5-pro-002' ],
    conversationId: 'conv_1758217649347_flu3zfddi',
    fileIds: [],
    workspaceId: 'default',
    priority: 0,
    skipCache: false,
    enhanceWithKnowledge: true,
    enableLearning: true
  },
  level: 'info',
  message: 'New query submitted',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  priority: 0,
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Query job added to queue',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'c849cfbe-eb3b-4981-b6e4-6ccb63ead099',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/v1/queries',
  statusCode: 202,
  responseTime: 20,
  userId: null,
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 309,
  userId: null,
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a73874b8-a5ef-470d-b426-9707f997b476',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 98,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:29',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a73874b8-a5ef-470d-b426-9707f997b476',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'c849cfbe-eb3b-4981-b6e4-6ccb63ead099',
  totalTime: 102,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-18 18:47:29'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: 'c849cfbe-eb3b-4981-b6e4-6ccb63ead099',
  timestamp: '2025-09-18 18:47:29',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '22',
  timestamp: '2025-09-18 18:47:29',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '22',
  jobType: 'processQuery',
  attempts: 1,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758217649347_flu3zfddi',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a'
    },
    requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a'
  },
  timestamp: '2025-09-18 18:47:29',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'e214c142-71e7-4e46-97c1-c18412b5d706',
  queryId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  level: 'info',
  message: 'Query result requested',
  timestamp: '2025-09-18 18:47:30'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/queries/8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  statusCode: 404,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:47:30',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  statusCode: 200,
  responseTime: 5,
  userId: null,
  timestamp: '2025-09-18 18:47:30',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:47:31'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'fa490cea-2e92-4628-8235-53a0037f0bae',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-18 18:47:31'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '7e73d04f-46e3-4d50-a6db-17333f21f57e',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:31'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 93,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:32',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '7e73d04f-46e3-4d50-a6db-17333f21f57e',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:32'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: 'fa490cea-2e92-4628-8235-53a0037f0bae',
  totalTime: 98,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-18 18:47:32'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: 'fa490cea-2e92-4628-8235-53a0037f0bae',
  timestamp: '2025-09-18 18:47:32',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '22',
  timestamp: '2025-09-18 18:47:32',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '22',
  jobType: 'processQuery',
  attempts: 2,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758217649347_flu3zfddi',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a'
    },
    requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a'
  },
  timestamp: '2025-09-18 18:47:32',
  level: 'error'
}
{
  message: 'Successfully discovered 13 models from google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:47:35'
}
{
  message: 'API key validated successfully with detected provider: google',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 18:47:35'
}
{
  service: 'enhanced-ai-pipeline',
  keyPrefix: 'AIzaSy...',
  provider: 'google',
  providerName: 'Google AI',
  modelsDiscovered: 13,
  ip: '127.0.0.1',
  userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',
  requestId: 'a0560dc1-2af3-49bb-8de8-3deb532c9d35',
  level: 'info',
  message: 'API key validated and models discovered',
  timestamp: '2025-09-18 18:47:35'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/api/save-key',
  statusCode: 200,
  responseTime: 77,
  userId: null,
  timestamp: '2025-09-18 18:47:35',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  jobId: '22',
  requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Processing query job',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '3a56162c-d9b0-4d72-ae60-81b6ac1d7c34',
  modelsCount: 1,
  selectedModels: [ 'gemini-1.5-pro-002' ],
  level: 'info',
  message: 'Starting parallel model calls',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'b4ce98c7-a46f-4d0b-8f22-6ce9c29cdc72',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-pro-002',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-pro-002',
  promptLength: 50,
  responseLength: 0,
  responseTime: 90,
  error: 'Request failed with status code 429',
  timestamp: '2025-09-18 18:47:38',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'b4ce98c7-a46f-4d0b-8f22-6ce9c29cdc72',
  level: 'warn',
  message: 'Rate limit hit for gemini-1.5-pro-002, retry after 60s',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  queryId: '3a56162c-d9b0-4d72-ae60-81b6ac1d7c34',
  totalTime: 91,
  successful: 0,
  failed: 1,
  level: 'info',
  message: 'Parallel model calls completed',
  timestamp: '2025-09-18 18:47:38'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'multiModelMerge',
  operation: 'callModelsInParallel',
  queryId: '3a56162c-d9b0-4d72-ae60-81b6ac1d7c34',
  timestamp: '2025-09-18 18:47:38',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  operation: 'processQueryJob',
  jobId: '22',
  timestamp: '2025-09-18 18:47:38',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'error',
  message: 'Application Error All model calls failed',
  stack: 'Error: All model calls failed\n' +
    '    at MultiModelMerge.callModelsInParallel (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\core\\multiModelMerge.js:501:15)\n' +
    '    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n' +
    '    at async QueueManager.processQueryJob (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:148:28)\n' +
    '    at async Queue.<anonymous> (C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\backend\\enhanced-ai-pipeline\\src\\utils\\queueManager.js:87:14)',
  component: 'queueManager',
  queue: 'queryProcessing',
  jobId: '22',
  jobType: 'processQuery',
  attempts: 3,
  data: {
    query: 'I want to learn programming, where should I start?',
    options: {
      selectedModel: 'gemini-1.5-pro-002',
      selectedModels: [ 'gemini-1.5-pro-002' ],
      conversationId: 'conv_1758217649347_flu3zfddi',
      fileIds: [],
      workspaceId: 'default',
      priority: 0,
      skipCache: false,
      enhanceWithKnowledge: true,
      enableLearning: true,
      requestId: '2094ec2e-0895-4b53-b6b4-1218c03cfc2a'
    },
    requestId: '8a4c32f4-1865-4aa0-b9bd-91028957bc3a'
  },
  timestamp: '2025-09-18 18:47:38',
  level: 'error'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 36,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '7f287bfd-a665-4802-b3e4-3c0efc791e49',
  query: 'Please answer clearly and concisely.',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '7f287bfd-a665-4802-b3e4-3c0efc791e49',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '64c8b27b-bd3c-4ce3-bf3f-82fcee663562',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 36,
  responseLength: 26,
  responseTime: 423,
  error: null,
  timestamp: '2025-09-18 18:47:42',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '7f287bfd-a665-4802-b3e4-3c0efc791e49',
  processingTime: 423,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:47:42'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 425,
  userId: null,
  timestamp: '2025-09-18 18:47:42',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/7f287bfd-a665-4802-b3e4-3c0efc791e49',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:47:43',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: [ 'gemini-1.5-flash' ],
  messageLength: 50,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'dce28dca-c169-428f-b2cd-39af0b9c2203',
  query: 'I want to learn programming, where should I start?',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'dce28dca-c169-428f-b2cd-39af0b9c2203',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a35ab8ee-e59d-4029-ba8a-da8b42f2d119',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:47:51'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 50,
  responseLength: 3866,
  responseTime: 6411,
  error: null,
  timestamp: '2025-09-18 18:47:57',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'dce28dca-c169-428f-b2cd-39af0b9c2203',
  processingTime: 6411,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:47:57'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 6414,
  userId: null,
  timestamp: '2025-09-18 18:47:57',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/dce28dca-c169-428f-b2cd-39af0b9c2203',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:47:58',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 3,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  query: 'hi ',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '69a83dc8-d2d2-4ef5-952a-96de40b2782e',
  modelId: 'gemini-1.5-flash',
  promptLength: 3,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:50:58'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 3,
  responseLength: 36,
  responseTime: 543,
  error: null,
  timestamp: '2025-09-18 18:50:59',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  processingTime: 545,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:50:59'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 548,
  userId: null,
  timestamp: '2025-09-18 18:50:59',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/cbb7beaa-61b7-4481-8ea9-c2cac7dffe32',
  statusCode: 200,
  responseTime: 2,
  userId: null,
  timestamp: '2025-09-18 18:50:59',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 56,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '89101e39-7bb3-42af-b2d8-8f707448a0b0',
  query: 'i want you to help me find the best ai models for coding',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '89101e39-7bb3-42af-b2d8-8f707448a0b0',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '82c30513-d578-48a5-b936-24e9138be46b',
  modelId: 'gemini-1.5-flash',
  promptLength: 56,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 18:51:27'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 56,
  responseLength: 3386,
  responseTime: 5433,
  error: null,
  timestamp: '2025-09-18 18:51:32',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '89101e39-7bb3-42af-b2d8-8f707448a0b0',
  processingTime: 5434,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 18:51:32'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 5437,
  userId: null,
  timestamp: '2025-09-18 18:51:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/89101e39-7bb3-42af-b2d8-8f707448a0b0',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 18:51:32',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 10,
  userId: null,
  timestamp: '2025-09-18 18:54:08',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/health',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-18 18:57:42',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 30,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '1d655734-4520-4c5d-9233-e9b5b7b7256a',
  query: 'give me the name of the best 3',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '1d655734-4520-4c5d-9233-e9b5b7b7256a',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '797367d3-2fff-4dfc-965a-41e976fd8715',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:00:55'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 30,
  responseLength: 189,
  responseTime: 887,
  error: null,
  timestamp: '2025-09-18 19:00:56',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '1d655734-4520-4c5d-9233-e9b5b7b7256a',
  processingTime: 887,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:00:56'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 889,
  userId: null,
  timestamp: '2025-09-18 19:00:56',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/1d655734-4520-4c5d-9233-e9b5b7b7256a',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:00:56',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 9,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ab350d65-9c88-4e4e-b590-26055980c125',
  query: 'ai models',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'ab350d65-9c88-4e4e-b590-26055980c125',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '8307826d-05e5-41a7-aed1-1ff424eaad9c',
  modelId: 'gemini-1.5-flash',
  promptLength: 9,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:01:12'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 9,
  responseLength: 3828,
  responseTime: 5821,
  error: null,
  timestamp: '2025-09-18 19:01:18',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'ab350d65-9c88-4e4e-b590-26055980c125',
  processingTime: 5822,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:01:18'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 5825,
  userId: null,
  timestamp: '2025-09-18 19:01:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/ab350d65-9c88-4e4e-b590-26055980c125',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:01:18',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 75,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  query: 'give me the name of the best 3 ai models only with  the budjet of 20 doller',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: '99e2b907-fa3b-4548-bc16-8c30ca5817f0',
  modelId: 'gemini-1.5-flash',
  promptLength: 75,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:02:09'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 75,
  responseLength: 759,
  responseTime: 1625,
  error: null,
  timestamp: '2025-09-18 19:02:11',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  processingTime: 1625,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:02:11'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 1627,
  userId: null,
  timestamp: '2025-09-18 19:02:11',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/41446dde-80e0-4bd5-b932-f1d83d0ca9eb',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:02:11',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 88,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '24eba698-d8cb-45df-b42a-de49bbc128ac',
  query: 'give me the name of the best 3 ai models only in programing with the budjet of 20 doller',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: '24eba698-d8cb-45df-b42a-de49bbc128ac',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'a668bd4b-5b1e-4738-a485-66d1c72f46f5',
  modelId: 'gemini-1.5-flash',
  promptLength: 88,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:02:33'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 88,
  responseLength: 1794,
  responseTime: 3169,
  error: null,
  timestamp: '2025-09-18 19:02:36',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: '24eba698-d8cb-45df-b42a-de49bbc128ac',
  processingTime: 3172,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:02:36'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 3174,
  userId: null,
  timestamp: '2025-09-18 19:02:36',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/24eba698-d8cb-45df-b42a-de49bbc128ac',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:02:36',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  model: 'gemini-1.5-flash',
  models: undefined,
  messageLength: 113,
  level: 'info',
  message: 'Processing chat message directly',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  query: 'give me the name of the best 3 ai models only in coding with the budjet of 20 doller answer with the',
  level: 'info',
  message: 'Direct processing query',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  models: [ 'gemini-1.5-flash' ],
  taskId: 'f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  level: 'info',
  message: 'Processing with models',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  requestId: 'bc8d1fb9-07f2-409e-a16a-9aa51eaf26fb',
  modelId: 'gemini-1.5-flash',
  promptLength: 113,
  level: 'info',
  message: 'Calling model gemini-1.5-flash',
  timestamp: '2025-09-18 19:03:11'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'model_call',
  modelId: 'gemini-1.5-flash',
  promptLength: 113,
  responseLength: 331,
  responseTime: 1033,
  error: null,
  timestamp: '2025-09-18 19:03:12',
  level: 'info',
  message: 'Model Call'
}
{
  service: 'enhanced-ai-pipeline',
  taskId: 'f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  processingTime: 1035,
  level: 'info',
  message: 'Query processed successfully',
  timestamp: '2025-09-18 19:03:12'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'POST',
  url: '/chat',
  statusCode: 200,
  responseTime: 1036,
  userId: null,
  timestamp: '2025-09-18 19:03:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/result/f32713d3-fe89-42ef-94ce-3aaea5483ea7',
  statusCode: 200,
  responseTime: 1,
  userId: null,
  timestamp: '2025-09-18 19:03:12',
  level: 'info',
  message: 'API Call'
}
{
  service: 'enhanced-ai-pipeline',
  baseDir: 'C:\\Users\\Administrator\\Desktop\\neuroXopenhandsXhaggingface---Copy\\NeuroXopenhands\\neurochat\\neurochat\\workspaces',
  level: 'info',
  message: 'Workspace base directory initialized',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Redis ready for operations',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Redis connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'MongoDB connected successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Database connections initialized (Redis and MongoDB are optional)',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'MetaModel loaded from disk',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Loaded 0 training examples',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Model performance data loaded from cache',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Queue manager initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  message: 'Server initialized successfully',
  level: 'info',
  service: 'enhanced-ai-pipeline',
  timestamp: '2025-09-18 21:43:50'
}
{
  service: 'enhanced-ai-pipeline',
  port: 12000,
  host: '0.0.0.0',
  env: 'development',
  pid: 11192,
  level: 'info',
  message: 'Server started successfully',
  timestamp: '2025-09-18 21:43:50'
}
{
  service: 'enhanced-ai-pipeline',
  type: 'api_call',
  method: 'GET',
  url: '/api/v1/models/config',
  statusCode: 200,
  responseTime: 6,
  userId: null,
  timestamp: '2025-09-18 21:43:57',
  level: 'info',
  message: 'API Call'
}
